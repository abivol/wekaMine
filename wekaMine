#!/usr/bin/env groovy 

import durbin.weka.* 
import durbin.weka.FoldSets
import durbin.util.*

err = System.err // sugar
def bExceptionOccurred = false

// Get the command line options, print help if needed. 
options = ParseOptions(args)

// Expand the configuration file into a list of experiments. 
// Clinical file name is passed in so config can handle "ALL" attribute if present.
// otherwise it is ignored...
def totalExperiments
if (options.config){
	err.print "\nReading experiments from config..."
	allExperiments = new WekaMineConfig(options.config,options.clinical)
	err.println "${allExperiments.size()} experiments read from config. "
	//experiments = allExperiments[options.experimentRange]
	totalExperiments = allExperiments.size()
	experiments = allExperiments
}else if (options.flatConfig){
	
	err.println "DISABLED TEMPORARIALY... need to reconcile code for this and normal cfg..."
	System.exit(1);
	
	err.print "Reading experiment list..."
	experiments = new WekaMineConfig()
	if (options.experimentsPerJob){
		// If we're writing out a job list, don't actually read the whole file, just determine it's size
		totalExperiments = experiments.readFlat(options.flatConfig,(0..0))
	}else{
		totalExperiments = experiments.readFlat(options.flatConfig,options.experimentRange)
	}
	err.println "${experiments.size()} experiments read out of $totalExperiments file."
}

FoldSets foldsets;
if (options.foldsetsFile){
	foldsets = new FoldSets(options.foldsetsFile)	
}

// Write out a flat list of experiments if requested...
if (options.flatExperimentOut){
	println WekaMineResult.expHeadingStr
	System.out.withWriter{w->
		allExperiments.each{experiment->
			w << experiment.toOutputString()
			w << "\n"
		}
	}
	System.exit(0)
}

// Write out jobs and quit if that is requested...
if (options.experimentsPerJob){
	scriptFile = getClass().protectionDomain.codeSource.location.path	
	WekaMine.writeClusterJobList(args,totalExperiments,options.experimentsPerJob,scriptFile)
	System.exit(0)
}

err.println ""
// Create output files, a summary output, a features output, and a samples output.

def from = options.experimentRange.getFrom()
def to = options.experimentRange.getTo()
def rangeStr = "$from.$to"

fileOut = "${options.output}${rangeStr}.summary.csv" as String
err.println "Creating output file $fileOut"
out = new File(fileOut)

featuresOut = "${options.output}${rangeStr}.features.csv" as String
err.println "Creating features output file $featuresOut"
fout = new File(featuresOut)

samplesOut = "${options.output}${rangeStr}.testsamples.csv" as String
err.println "Creating samples output file $samplesOut"
sout = new File(samplesOut)

// Output information about training set if requested. 
def tout
if (options.evalTraining){
	trainingOut = "${options.output}${rangeStr}.trainingsamples.csv" as String	
	err.println "Creating samples output file $trainingOut"
	tout = new File(trainingOut)	
}

err.println ""

// Print a heading to the output files unless heading is suppressed (say, for cluster jobs)
if (!options.suppressHeading){
	
	if (options.validationFraction){
		out << WekaMineResults.getFormattedSummaryHeading() 
		out << ",holdoutAcc"
		out << "\n"
	}else{	
		out << WekaMineResults.getFormattedSummaryHeading() << "\n"
	}
	fout << WekaMineResults.getFormattedSummaryHeading() << "\n"
	sout << WekaMineResults.getFormattedSummaryHeading() << "\n"
}

// Read the data (expression, CNV, whatever) and the clinical from tab delimited files
if (options.dataMayContainNominalValues){
	err.println "Reading data with nominal values."
	data = WekaMine.readFromTable(options.data)
}else{
	err.println "Reading numeric data."
	data = WekaMine.readNumericFromTable(options.data)
}
//data = TableFileLoader.readNumeric(options.data,options.data,"\t");
clinical = WekaMine.readFromTable(options.clinical,instancesInRows = options.clinicalInstancesInRows)

// Remove everything except a subset if a list of samples to use is given.
if (options.sampleSubset){
	data = WekaMine.subsetInstances(data,options.sampleSubset)
	clinical = WekaMine.subsetInstances(clinical,options.sampleSubset)
}

//err.println "DEBUG: "+options.experimentRange
//experiments[options.experimentRange].eachWithIndex{exp,idx-> 
//	err.println "DEBUG experiment $idx"
//}

// Perform each experiment described in the experiment spec...
//experiments[options.experimentRange].eachWithIndex{exp,idx->  Experiments now subseted before here...
experiments[options.experimentRange].eachWithIndex{exp,idx-> 
	jobIdx = idx+options.experimentRange.getTo()
	err.println "------------------------------------------------"
	err.println "Experiment: $jobIdx \t Class attribute: ${exp.classAttribute}"
	try{
	
		// Creates a wekaMine pipeline...
		pipeline = new WekaMine(data,clinical,exp,experiments.params)		
		pipeline.dataName = options.data
		
		// Combines data and single class attribute from clinical into one set of instances...
		//instances = pipeline.createInstancesFromDataAndClinical(data,clinical,exp.classAttribute)	
		instances = pipeline.createInstancesFromDataAndClinical(data,clinical)	
		err.println "Combined instances: "+instances.numInstances()
		
		// Clean up instances:
		// * remove useless attributes
		// * if not allowed, remove instances with negative class values
		// * remove instances with missing class values	
		instances = pipeline.cleanUpInstances(instances)

		// Discretize the class attribute...
		(instances,cutoffs) = pipeline.discretizeClassAttribute(instances)	
		
		// Remove censored samples that can't be put into a discretized class... 
		// KJD Should these be removed?? Shouldn't their class just be set to unknown? 
		if (experiments.params.censoredAttribute){
			instances = pipeline.removeUnclassifiableCensoredSamples(instances,clinical,experiments.params.censoredAttribute)
		}
		
		// If a validation hold-out is requested, pull that set here.  Note that stratification ensres
		// that the hold out will have the same mix of nominal class attributes as the full dataset. 
		if (options.validationFraction){		
			//err.println "FEATURE DISABLED.  Feature is being tested and is not yet available. "
			//System.exit(1)
			
			holdoutInstances = pipeline.holdOutInstances(instances,options.validationFraction)
			holdoutInstanceIDs = holdoutInstances.attributeValues("ID") as ArrayList							
			err.println "Holding out ${holdoutInstances.numInstances()} stratified instances for validation:"
			instances = pipeline.remainingInstances(instances,options.validationFraction)
			err.println "***DEBUG:  num attributes: "+instances.numAttributes()
			println holdoutInstanceIDs
			err.println "Using ${instances.numInstances()} stratified instances for experiment."
		}

		// Create an attribute selected classifier from the given experiment description..
		asClassifier = pipeline.createAttributeSelectedClassifier()
						
		// Perform the cross validation
		err.println "AttSel:  ${exp.attrEvalStr}; ${exp.attrSearchStr} numAttrs: ${exp.numAttributes}"
		err.println "Classifier: ${exp.classifierStr}"
		err.println "Crossvalidating (${experiments.params.cvFolds} folds) model on ${instances.numInstances()} instances ${exp.classAttribute} ..."

		// Use seed or randomize with clock...
		def rng;
		if (experiments.params.cvSeed == -1){
			rng = new Random();
		}else{
			rng = new Random(experiments.params.cvSeed)
		}
				
		Evaluation2 eval 
		if (options.foldsetsFile){									
			eval = pipeline.crossValidateModelWithGivenFolds(asClassifier,instances,foldsets,options.evalTraining)
		}else{
			eval = pipeline.crossValidateModel(asClassifier,instances,experiments.params.cvFolds,rng,options.evalTraining)
		}
	
		if (options.validationFraction){						
			/*****
			* wmSaveModel...
			*/
			// Create a classifier from all of the non-validation samples...
			err.println "***EVALUATE HOLDOUT***"
			hinstances = pipeline.cleanUpInstances(instances)			
			(hinstances,cutoffs) = pipeline.discretizeClassAttribute(hinstances)
			err.println "Non-holdout instances class attribute discretized: $cutoffs"			
			hinstances = pipeline.removeInstanceID(hinstances)							
			err.println "DEBUG:  numAttributes: "+hinstances.numAttributes()	// This includes all attributes EXCEPt ID
			hinstances = pipeline.selectAttributes(hinstances)
			err.println "DEBUG:  numAttributes: "+hinstances.numAttributes() // This removes everything except the ones selected.
			err.print "Train model with non-holdout instances..."
			exp.classifier.buildClassifier(hinstances);
			err.println "done."		
			err.print("Create model object with classifier...")
			model = new WekaMineModel(hinstances,exp.classifier,cutoffs)				
			err.println("done.")
						
			/******
			* wmClassify
			*/ 
			err.println("Classify holdouts with trained model...")
			err.println "Holdout attributes: "+data.numAttributes()
			holdoutprocessed = InstanceUtils.createInstancesToMatchAttributeList(holdoutInstances,model.attributes) 
			err.println "holdoutprocessed attributes: "+holdoutprocessed.numAttributes()
			err.println "holdInstances attributes: "+holdoutInstances.numAttributes()
			holdoutprocessed = WekaMine.createEmptyClassAttribute(holdoutprocessed,model.className,model.classValues)
			holdoutprocessed.setClassName(model.className)
			results = model.classify(holdoutprocessed)
			clinical.setClassName(model.className)
			(clinicaldisc,cutoffs) = pipeline.discretizeClassAttribute(clinical)
			holdoutAccuracy = accuracy(results,holdoutInstanceIDs,clinicaldisc,model)
			err.println "\tHoldout accuracy: $holdoutAccuracy"		
			err.println "*** END EVALUATE HOLDOUT ***"
			err.print "Appending test results..."
			pipeline.appendSummaryWithHoldout(out,jobIdx,hinstances,holdoutAccuracy)
		}else{
			err.print "Appending test results..."
			pipeline.appendSummary(out,jobIdx,instances)
		}		
		pipeline.appendFeatures(fout,jobIdx,instances,options.maxFeaturesOut as Integer)
		pipeline.appendTestSamples(sout, jobIdx,instances)
		err.println "done."
		
		if (options.evalTraining){			
			err.print "Append training results..."
			pipeline.appendTrainingSamples(tout,jobIdx,instances)
			err.println "done."
		}		
		
		err.println "done. AUC=${eval.weightedAreaUnderROC()}"
	  err.println "==========================================\n"										
	}catch (Exception e){
		err.println "\n\n"
		err.println "Exception occurred."
		err.println e		
		// Save info about exception..
		bExceptionOccurred = true
	}
}	

if (bExceptionOccurred) {
	err.println "An exception occurred during this run."
	System.exit(1)
}else System.exit(0)
	
	// File doesn't have a close (as opposed to writer)... Are writes to File guaranteed to flush? 
	//out.close()
	//fout.close()
	//sout.close()
	//if (options.evalTraining) tout.close()
	
	// Quit with non-zero (positive) on exception. 
		




//============================================================================
// 


/****************************************************
* Parse the command line options, checking validity, printing help if needed. 
*/ 
def ParseOptions(args){
	parser = new Parser(description: '''
	 wekaMine takes a tab delimited data file in attributes (rows) x samples (cols) format, 
	 and a clinical file, also in attributes (rows) x samples (cols) format, and evaluates 
	 the set of experiments specified in an experimental configuration file.  Classification is 
	 performed on the samples that occur in both the data and clinical file (intersection). 
	 A list of summary lines in CSV format will be APPENDED to the end of the output file.  
	 Since this will often be run in a cluster setting with many jobs appending to the same 
	 file, the heading can optionally be omitted. 

	 Instances with missing class values are removed.   Attributes that do not vary at all 
	 are removed.  Instances with negative class values are optionally removed.  

	 The actual experiments and experimental options are provided by the config file (-c). 
	 Documentation for this config file can be found here:  

	 https://cancer2.cse.ucsc.edu/mediawiki/index.php/WekaClassifierConfig

	 Note that the config file can specify a number of attributes to use in attribute 
	 selection, or -1 to auto-select (the details of which varies from attribute selection 
	 algorithm to attribute selection algorithm). The config file option actually determines 
	 how many attributes the classifier sees.  The -m/maxFeaturesOut option merely determines 
	 the maximum number of selected attributes (and their scores) to save in the output and 
	 does not affect what attributes the classifier will see. 
	
	 An optional validation set can be held out from the cross-validation portion of the 
	 experiment.  Each model will be trained on all data not in the evaluation set and 
	 evaluated on the evaluation set.  The evaluation accuracy will be saved with roc and
	 other parameters, as a convenience, but should not be used to pick the best model. The
	 best model should be picked based on roc or other CV parameters, and the evaluation 
	 accuracy used only after-the-fact to verify that the model does predict something on 
	 an independent set.  That is, one should pretend that the evaluation set is only 
	 applied to the one best model, after picking the best model.  It is applied to all models
	 simply to avoid having to communicate the hold-out set between wekaMine and subsequent
	 model selection/building/evaluation steps. 
	
	 
	Written by: James Durbin (kdurbin@ucsc.edu)

	 Example:

	 wekaMine  \\
	 -d data/paradigm_results.txt -i data/collisonclinical.small.tab \\
	 -c exp/cfgExample2.txt -r 0,19 -s include.samples -o results/expout.csv

	''');

	parser.with{

	  required 'o','output',[description: 'File where output should go. Generates three files *.summary.csv, *.features.csv, and *.samples.csv']
	  required 'd','data', [description: 'Data file in attribute (row) by samples (col) format.']
	  required 'i','clinical', [description: 'Clinical file in attribute (row) by samples (col) format.']
	
		optional 'k','experimentsPerJob',[description: 'When specified, wekaMine does not run but instead outputs a list of wekaMine commands, k experiments each, for the cluster.']
		flag 'F','flatExperimentOut',[default:false,description: 'Does not perform experiments but merely writes their description to stdout.']

	  optional 'c','config',[description: 'Configuration file.  One of -c or -C required. ']  
		optional 'C','flatConfig',[description: 'A flat configuration file, one experiment per line. One of -c or -C required.']  

		optional 'f','foldsetsFile',[default:null,description: "File specifying the cross validation foldsets to use."]
	  optional 'm','maxFeaturesOut',[default: 100,description: "Maximum number of ranked features to output from cross-validation or full-set if classifier is 'None'"]
		optional 's','sampleSubset',[default:null,description: "File listing samples to use.  All other samples will be excluded from analysis.",
			validate:{
				if (it != null){				
					// Read in the samplesToUse... 
					def samplesToUse = []
					new File(it).eachLine{samplesToUse << it}
					return(samplesToUse)
				}else {
					return(it)							
				}
			}
		]

	  optional 'r','experimentRange',[default: "0,-1", description: 'Range of experiments to run (e.g. -r 54,67, mainly for cluster splits)',
			// Convert it to a proper range. Default is all inclusive range. 
			validate:{								
		 		experimentStart = (it.split(","))[0] as int
		 		experimentEnd = (it.split(","))[1] as int 
			  range = (experimentStart..experimentEnd)
				return(range)
			}]			
			
		optional 'v','validationFraction',[default:0.0,description: 'Fraction of samples to withold from cross-validation portion of experiment, evaluating only at end on fully trained model.',
		validate:{it as double}]		

		flag 't','evalTraining',[default:false,description:'If set, the classifier is evaluated on the training data as well as the test data in cross validation, output in *.trainingsamples.csv.  NOTE: This will slow down execution, possibly significantly.' ]
		flag 'R','clinicalInstancesInRows',[default:false,description:'If set, clinical data will be assumed to be one instance per row. Default one instance per column.']		
		flag 'H','suppressHeading',[default:false,description: 'Suppress heading for summary.csv. (to make easier to cat cluster job outputs)']
		flag 'N','dataMayContainNominalValues',[default:false,description: 'Option to read datafile in as mixed numeric/nominal.  Slower than default all numeric. ']
	  flag 'h','help',[default:false,description: 'Print script help.']
	}

	def options
	try{
	  options = parser.parse(args)
	
		if (!(options.config || options.flatConfig)){
			System.err.println "A config file must be specified with either -c or -C."
			System.err<<parser.usage
			System.exit(1)
		}		
		
		if (options.config && options.flatConfig){
			System.err.println "Specify only ONE of options -c or -C "
			System.err<<parser.usage
			System.exit(1)
		}
		
	}catch(Exception e){
	  System.err << parser.usage
	  System.exit(1)
	}	
	return(options)
}


def accuracy(results,holdoutInstanceIDs,clinical,model){	
	classValues = model.classValues
	//err.println "\t$classValues"
	double correct = 0;
	double total = 0;
	holdoutInstanceIdxs = clinical.nameListToIndexList(holdoutInstanceIDs)
	holdoutInstanceIDs.eachWithIndex{instanceID,i->
		instIdx = holdoutInstanceIdxs[i]
		clinicalInst = clinical[instIdx]
		clinicalValue = clinicalInst[model.className]
		distForInstance = results[i]
		//err.println "\t$instanceID\t$distForInstance\t$clinicalValue"
		maxIdx = maxIdx(distForInstance)
		if (classValues[maxIdx] == clinicalValue){
			correct++
		}
		total++
	}	
	return(correct/total)
}


def maxIdx(dist){
	def maxval = -999
	def maxidx = -1
	dist.eachWithIndex{val,i->
		if (val > maxval){
			maxval = val
			maxidx = i
		}		
	}	
	return(maxidx)		
}


