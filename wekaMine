#!/usr/bin/env groovy 

import durbin.weka.* 
import durbin.weka.FoldSets
import durbin.util.*

err = System.err // sugar

// Get the command line options, print help if needed. 
options = ParseOptions(args)

// Expand the configuration file into a list of experiments. 
experiments = new WekaMineConfig(options.config)

FoldSets foldsets;
if (options.foldsetsFile){
	foldsets = new FoldSets(options.foldsetsFile)	
}

// Write out jobs and quit if that is requested...
if (options.experimentsPerJob){
	scriptFile = getClass().protectionDomain.codeSource.location.path	
	WekaMine.writeClusterJobList(args,experiments.size(),options.experimentsPerJob,scriptFile)
	System.exit(0)
}


err.println ""
// Create output files, a summary output, a features output, and a samples output.

def from = options.experimentRange.getFrom()
def to = options.experimentRange.getTo()
def rangeStr = "$from.$to"

fileOut = "${options.output}${rangeStr}.summary.csv" as String
err.println "Creating output file $fileOut"
out = new File(fileOut)

featuresOut = "${options.output}${rangeStr}.features.csv" as String
err.println "Creating features output file $featuresOut"
fout = new File(featuresOut)

samplesOut = "${options.output}${rangeStr}.testsamples.csv" as String
err.println "Creating samples output file $samplesOut"
sout = new File(samplesOut)

// Output information about training set if requested. 
def tout,tsout
if (options.evalTraining){
	trainingOut = "${options.output}${rangeStr}.trainingsamples.csv" as String	
	err.println "Creating samples output file $trainingOut"
	tout = new File(trainingOut)	
}

err.println ""

// Print a heading to the output files unless heading is suppressed (say, for cluster jobs)
if (!options.suppressHeading){
	out << WekaMineResults.getFormattedSummaryHeading() << "\n"
	fout << WekaMineResults.getFormattedSummaryHeading() << "\n"
	sout << WekaMineResults.getFormattedSummaryHeading() << "\n"
}

// Read the data (expression, CNV, whatever) and the clinical from tab delimited files
data = WekaMine.readNumericFromTable(options.data)
//data = TableFileLoader.readNumeric(options.data,options.data,"\t");
clinical = WekaMine.readFromTable(options.clinical,instancesInRows = options.clinicalInstancesInRows)

//err.println clinical

// Perform each experiment described in the experiment spec...
//experiments[options.experimentRange].eachWithIndex{exp,idx-> 
experiments[options.experimentRange].eachWithIndex{exp,idx-> 
	jobIdx = idx+options.experimentRange.getTo()
	err.println "Experiment: $jobIdx"
	try{
	
		// Creates a wekaMine pipeline...
		pipeline = new WekaMine(data,clinical,exp,experiments.params)		
		pipeline.dataName = options.data
		
		// Combines data and single class attribute from clinical into one set of instances...
		//instances = pipeline.createInstancesFromDataAndClinical(data,clinical,exp.classAttribute)	
		instances = pipeline.createInstancesFromDataAndClinical(data,clinical)	

		// Remove everything except a subset if a list of samples to use is given.
		if (options.sampleSubset){
			instances = WekaMine.subsetInstances(instances,options.sampleSubset)
		}
		
		// Clean up instances:
		// * remove useless attributes
		// * if not allowed, remove instances with negative class values
		// * remove instances with missing class values	
		instances = pipeline.cleanUpInstances(instances)

		// Discretize the class attribute...
		instances = pipeline.discretizeClassAttribute(instances)	
		
		// Remove censored samples that can't be put into a discretized class... 
		if (experiments.params.censoredAttribute){
			instances = pipeline.removeUnclassifiableCensoredSamples(instances,clinical,experiments.params.censoredAttribute)
		}
		
		// Fix up the foldset to match the remaining instances...
		if (options.foldsetsFile){
			err.print "Fix foldset to reflect removed samples..."
			foldsets = foldsets.removeMissing(instances)
			experiments.params.cvFolds = foldsets.countFolds()
			err.println "done."
		}

		// Create an attribute selected classifier from the given experiment description..
		asClassifier = pipeline.createAttributeSelectedClassifier()
						
		// Perform the cross validation
		err.println "AttSel:  ${exp.attrEvalStr} numAttrs: ${exp.numAttributes}"
		err.println "Classifier: ${exp.classifierStr}"
		err.print "Crossvalidating (${experiments.params.cvFolds} folds) model on ${instances.numInstances()} instances ${exp.classAttribute} ..."

		// Use seed or randomize with clock...
		def rng;
		if (experiments.params.cvSeed == -1){
			rng = new Random();
		}else{
			rng = new Random(experiments.params.cvSeed)
		}
				
		Evaluation2 eval 
		if (options.foldsetsFile){
			eval = pipeline.crossValidateModelWithGivenFolds(asClassifier,instances,foldsets,options.evalTraining)
		}else{
			eval = pipeline.crossValidateModel(asClassifier,instances,experiments.params.cvFolds,rng,options.evalTraining)
		}
		err.println "done. AUC=${eval.weightedAreaUnderROC()}"
	  err.println "==========================================\n"
	
		pipeline.appendSummary(out,jobIdx,instances)
		pipeline.appendFeatures(fout,jobIdx,instances,options.maxFeaturesOut as Integer)
		pipeline.appendTestSamples(sout, jobIdx,instances)
		
		if (options.evalTraining){
			pipeline.appendTrainingSamples(tout,jobIdx,instances)
		}
		
			
	}catch (Exception e){
		err.println "\n\n"
		err.println e
		// Save info about exception..
	}
}



//============================================================================
// 


/****************************************************
* Parse the command line options, checking validity, printing help if needed. 
*/ 
def ParseOptions(args){
	parser = new Parser(description: '''
	 wekaMine takes a tab delimited data file in attributes (rows) x samples (cols) format, 
	 and a clinical file, also in attributes (rows) x samples (cols) format, and evaluates 
	 the set of experiments specified in an experimental configuration file.  Classification is 
	 performed on the samples that occur in both the data and clinical file (intersection). 
	 A list of summary lines in CSV format will be APPENDED to the end of the output file.  
	 Since this will often be run in a cluster setting with many jobs appending to the same 
	 file, the heading can optionally be omitted. 

	 Instances with missing class values are removed.   Attributes that do not vary at all 
	 are removed.  Instances with negative class values are optionally removed.  

	 The actual experiments and experimental options are provided by the config file (-c). 
	 Documentation for this config file can be found here:  

	 https://cancer2.cse.ucsc.edu/mediawiki/index.php/WekaClassifierConfig

	 Note that the config file can specify a number of attributes to use in attribute 
	 selection, or -1 to auto-select (the details of which varies from attribute selection 
	 algorithm to attribute selection algorithm). The config file option actually determines 
	 how many attributes the classifier sees.  The -m/maxFeaturesOut option merely determines 
	 the maximum number of selected attributes (and their scores) to save in the output and 
	 does not affect what attributes the classifier will see. 
	
	 
	Written by: James Durbin (kdurbin@ucsc.edu)

	 Example:

	 wekaMine  \\
	 -d data/paradigm_results.txt -i data/collisonclinical.small.tab \\
	 -c exp/cfgExample2.txt -r 0,19 -s include.samples -o results/expout.csv

	''');

	parser.with{

	  required 'o','output',[description: 'File where output should go. Generates three files *.summary.csv, *.features.csv, and *.samples.csv']
	  required 'c','config',[description: 'Configuration file']  
	  required 'd','data', [description: 'Data file in attribute (row) by samples (col) format.']
	  required 'i','clinical', [description: 'Clinical file in attribute (row) by samples (col) format.']
	
		optional 'k','experimentsPerJob',[description: 'When specified, wekaMine does not run but instead outputs a list of wekaMine commands, k experiments each, for the cluster.']

		optional 'f','foldsetsFile',[default:null,description: "File specifying the cross validation foldsets to use."]
	  optional 'm','maxFeaturesOut',[default: 100,description: "Maximum number of ranked features to output from cross-validation or full-set if classifier is 'None'"]
		optional 's','sampleSubset',[default:null,description: "File listing samples to use.  All other samples will be excluded from analysis.",
			validate:{
				if (it != null){				
					// Read in the samplesToUse... 
					def samplesToUse = []
					new File(it).eachLine{samplesToUse << it}
					return(samplesToUse)
				}else {
					return(it)							
				}
			}
		]

	  optional 'r','experimentRange',[default: "0,-1", description: 'Range of experiments to run (e.g. -r 54,67, mainly for cluster splits)',
			// Convert it to a proper range. Default is all inclusive range. 
			validate:{								
		 		experimentStart = (it.split(","))[0] as int
		 		experimentEnd = (it.split(","))[1] as int 
			  range = (experimentStart..experimentEnd)
				return(range)
			}]			

		flag 't','evalTraining',[default:false,description:'If set, the classifier is evaluated on the training data as well as the test data in cross validation, output in *.trainingsamples.csv.  NOTE: This will slow down execution, possibly significantly.' ]
		flag 'R','clinicalInstancesInRows',[default:false,description:'If set, clinical data will be assumed to be one instance per row. Default one instance per column.']		
		flag 'H','suppressHeading',[default:false,description: 'Suppress heading for summary.csv. (to make easier to cat cluster job outputs)']
	  flag 'h','help',[default:false,description: 'Print script help.']
	}

	def options
	try{
	  options = parser.parse(args)
	}catch(Exception e){
	  System.err << parser.usage
	  System.exit(1)
	}	
	return(options)
}
