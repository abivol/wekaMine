#!/usr/bin/env groovy

import durbin.weka.* 
import durbin.util.*
import weka.core.converters.ConverterUtils.DataSource;
import weka.core.*

err = System.err // sugar

WekaAdditions.enable()

// Get the command line options, print help if needed. 
options = ParseOptions(args)

// Read the data (expression, CNV, whatever) 
instances = WekaMine.readNumericFromTable(options.data)

// read model list
def modelList = []
if (options.modelList){
	fileContents = new File(options.modelList).text
	modelList = fileContents.split("\n") as ArrayList
}

// Or just read a directory of models...
if (options.modelDir){
		new File(options.modelDir).eachFileMatch(~/.*\.wmm/){modelName->
			fullName = modelName.canonicalPath
			modelList<<fullName
		}
}

modelsBySamples = new DynamicTable()
modelList.each{modelName->
	
	if (options.rootPath) modelPath = options.rootPath
	else modelPath = ""
	
	err.print "Reading model ${modelName} ..."
	model = (WekaMineModel) weka.core.SerializationHelper.read("${modelPath}/${modelName}");
	err.println "done."	
	
	if ((options.useNullModel) && (model.bnm == null)){
		err.println "ERROR: Attempt to use bootstrap null model, but none found in $modelName"
		System.exit(1)
	}

	// Create a new set of instances that match the model set... this may mean removing
	// some attributes that are not in the model and/or adding some that are in the model 
	// but not in the data (set as missing values in this case).   Performance on datasets
	// with different attribute sets will vary with algorithm and problem, but wekaMineClassify
	// will attempt to apply the model to any dataset it is given. 

	// The raw instances will, if nothing else,probably not be attribute selected, so a minimal
	// effect of this will be to reduce the number of attributes significantly down to the 
	// attribute selected subset of the model...

	// The model has no ID, so we save the ID for later reporting...
	instanceIDs = instances.attributeValues("ID") as ArrayList

	matchedInstances = WekaMine.createInstancesToMatchAttributeList(instances,model.attributes)

	// Add an empty class attribute so that classifiers don't choke ? Odd...
	matchedInstances = WekaMine.createEmptyClassAttribute(matchedInstances,model.className,model.classValues)
	matchedInstances.setClassName(model.className)
	
	// Model knows everything else needed to process the data... so have at it...
	// Results is a list, one item per instance, each item is a distribution for instance
	// results[0] == model.class0 probability, results[1] == model.class1 probability. 
	results = model.classify(matchedInstances)
	
	// KJD should have an option to take the name of the class you want to report...
	// (i.e. brain or not-brain).  Currently just takes first class value.  Also, this is 
	// poorly defined for multi-class distributions. 
	if (options.useNullModel){	
		for(instanceIdx in 0..< matchedInstances.numInstances()){		
			instanceName = instanceIDs[instanceIdx]
			class0Pr = results[instanceIdx][0]  
			class1Pr = results[instanceIdx][1]
			null0Pr = model.bnm.getSignificance(class0Pr,0)
			null1Pr = model.bnm.getSignificance(class1Pr,1)		
			llr = Math.log(null1Pr/null0Pr)		
			modelsBySamples[modelName][instanceName] = llr.round(7)
		}
	}else if (options.writeAll){
			instanceName = instanceIDs[instanceIdx]
			class0Pr = results[instanceIdx][0]  
			class1Pr = results[instanceIdx][1]
			null0Pr = model.bnm.getSignificance(class0Pr,0)
			null1Pr = model.bnm.getSignificance(class1Pr,1)
			outStr = "${class0Pr.round(7)},${class1Pr.round(7)},${null0Pr.round(7)},${null1Pr.round(7)}"
			modelsBySamples[modelName][instanceName] = outStr
	}else{	
		for(instanceIdx in 0..< matchedInstances.numInstances()){		
			instanceName = instanceIDs[instanceIdx]
			class0Pr = results[instanceIdx][0]  
			class1Pr = results[instanceIdx][1]
			llr = Math.log(class1Pr/class0Pr)		
			modelsBySamples[modelName][instanceName] = llr.round(7)
		}
	}

}

def out = System.out
if (options.outputFile) out = new File(options.outputFile)

err.print "Writing ${options.outputFile}.."
modelsBySamples.writeTable(out)
err.println "done."


/****************************************************
* Parse the command line options, checking validity, printing help if needed. 
*/ 
def ParseOptions(args){
	parser = new Parser(description: '''
	
	wmCreateChain takes a list of models and applies them one at a time to the input data. The result of 
	each classifier output (distForInstance value...) is saved in a model (rows) by samples (cols) table. 
	 
	Written by: James Durbin (kdurbin@ucsc.edu)

	Example:


	''');

	parser.with{
				
	  required 'd','data', [description: 'Data file in attribute (row) by samples (col) format.']

		optional 'm','modelList',[description: 'A list of model file paths. One of -m or -M required. ']
    optional 'M','modelDir',[description: 'A directory of model files. Only files with .wmm extension will be considered. One of -m or -M required. ']

		optional 'o','outputFile',[description: 'Output file.  If none given, output goes to stdout.']
		optional 'p','rootPath',[description: 'Root path appended to beginning of each model name.']

		flag 'W','writeAll',[description: 'Write both probabilities and bootstrap null probabilities for each value like: pr1,pr2,null1,null2']
		flag 'N','useNullModel',[description: 'Use bootstrap null model instead of classifier confidence to compute LLR.']
	  flag 'h','help',[default:false,description: 'Print script help.']	
	
	}
	
	def options
	try{
	  options = parser.parse(args)
	
		if (!(options.modelDir || options.modelList)){
			System.err.println "Model files must be specified with either -m or -M."
			System.err<<parser.usage
			System.exit(1)
		}
	
	}catch(Exception e){
	  System.err << parser.usage
	  System.exit(1)
	}	
	
	return(options)
}
