#!/usr/bin/env groovy 

import durbin.util.*
import durbin.weka.*

// KJD: Should probably bundle this into wekaMine somehow...

err = System.err

parser = new Parser(description: '''
  Creates a list of script commands ready to execute with para try and para run.  Output is to stdout. 
    
  createParasolJobs -s ./scripts/ -d tcga_ov_both_pathwayentities.tab -i OV_clinicalTable.txt -p params.txt -l few.txt -o exp.out > jobList
  createParasolJobs -o results/test.out -d data/tcga_ov_both_pathwayentities.tab -i data/OV_clinicalTable.txt -c lists/cfgExample2.txt  -s ./scripts/
  
  Be sure that -o is a cluster appropriate output, not your home directory. 
  
''');

// /hive/users/james/bin/
parser.with{ 
  required 's','scriptRoot',[description: 'Path to the directory containing paradigmClassifierBulkEval.']
  required 'd','data', [description: 'Data file in attribute (row) by samples (col) format.']
  required 'i','clinical', [description: 'Clinical file in attribute (row) by samples (col) format.']
  required 'o','outputFileRoot',[description: 'Root name of file where output will be concatenated to']
  optional 'c','configFile',[description: 'Config file (possibly with embedded experiments.)']
  optional 'n','numExperimentsPerJob',[default: 20,description: 'Number of experiments per cluster job. ',
                                       validate: {it as Integer}]
      
  optional 'm','maxFeaturesOut',[default: 0,description: "Maximum number of ranked features to output.",
                                 validate:{it as Integer}]
                                 
  optional 'R','raFileRoot',[description: 'Root path of .ra files for loading into classifier browser.(e.g. ./ra/chin2006)']
  
  //optional 'l','listOutput',[description: 'File name for a flat list output of the experiments.']
  flag 'h','help',[default:false,description: 'Print script help.']
}

def options
try{
  options = parser.parse(args)
}catch(Exception e){
  System.err << parser.usage
  System.exit(1)
}

// Go ahead and write a heading to the output file.  Used to do this in the eval script itself
// but that generated lots of headings where we only want one. 
out = new File(options.outputFileRoot)
summaryHeading = WekaMineResults.getFormattedSummaryHeading()
out << "${summaryHeading},classifier, attributeEval,attributeSearch,numAttributes,classAttribute"

if (options.maxFeaturesOut > 0){
	err.println "DEBUG: ${options.maxFeaturesOut}"
  out<< ","+WekaMineResults.getAttributesHeading(options.data,options.maxFeaturesOut)
}
out<<"\n"

def listout
if (options.configFile && options.listOutput){
  listout = new File(options.listOutput)
}

// Figure out how many jobs we need based on the number of experiments given. 
def numExperiments,numJobs

// Parse config file, expanding all experiments, to determine the number...
def slurper = new WekaExplorerConfigSlurper()
def cfg = slurper.parse(new File(options.configFile).toURL())
experiments = []
slurper.getExpansion('experiments').each{experiment->
  experiments << new ExperimentSpec(experiment);    
        
  // TODO:  This needs work, as currently still require outputFile even though it
  // doesn't use it...
  if (options.configFile && options.listOutput){
    listout << experiment+"\n"
  }    
}
numExperiments = experiments.size()
numJobs = (double)numExperiments/(double)options.numExperimentsPerJob
System.err.println("numExperiments: $numExperiments  numJobs: $numJobs")
  
// Only wanted to write out the list file...
if (options.configFile && options.listOutput){
  System.exit(0)
}
    

//System.err.println "numExp: "+numExperiments+" numJobs: "+numJobs;

if (options.experimentList){
  rootCmd = "${options.scriptRoot}/wekaMine -d ${options.data} -i ${options.clinical}"
  rootCmd += " -c ${options.configFile} -l ${options.experimentList}"
}else if (options.configFile){
  rootCmd = "${options.scriptRoot}/wekaMine -d ${options.data} -i ${options.clinical}"
  rootCmd += " -c ${options.configFile}"
  rootCmd += " -m ${options.maxFeaturesOut}"
}else{
  System.err.println "ERROR: Must specify one of -c or -l."
  System.err<<parser.usage
  System.exit(1)
}

if (options.raFileRoot){
  rootCmd += " -R ${options.raFileRoot}"
}


// KJD: Note.. eventually I will add something in the jobs to indicate their expected time so that 
// jobs can be constructed to be approximately equal time.   Thus, there might be 20 SVM experiments 
// in a job, but only one perceptron experiment. 

jobStart = 0
jobEnd = options.numExperimentsPerJob -1;
(0..<numJobs).each{
  cmdOut = rootCmd + " -r $jobStart,$jobEnd -o ${options.outputFileRoot}"
  println cmdOut
  jobStart += options.numExperimentsPerJob
  jobEnd += options.numExperimentsPerJob  
}

// Handle remainder experiments..

lastExperiment = (jobEnd-options.numExperimentsPerJob)
if (lastExperiment < numExperiments){
  jobStart = lastExperiment+1
  jobEnd = numExperiments-1
  cmdOut = rootCmd + " -r $jobStart,$jobEnd -o ${options.outputFileRoot}".toString()
  println cmdOut
}


/*
Example: 

/scripts/createParasolJobs -s ./scripts/ -d data/tcga_ov_both_pathwayentities.tab -i data/OV_clinicalTable.txt -p lists/params.txt -l lists/experimentlist.txt -o temp/exp.out 
numExp: 576 numJobs: 28.8
./scripts//paradigmClassifierBulkEval -d data/tcga_ov_both_pathwayentities.tab -i data/OV_clinicalTable.txt -c lists/params.txt -l lists/experimentlist.txt -r 0,19 >> temp/exp.out
./scripts//paradigmClassifierBulkEval -d data/tcga_ov_both_pathwayentities.tab -i data/OV_clinicalTable.txt -c lists/params.txt -l lists/experimentlist.txt -r 20,39 >> temp/exp.out
./scripts//paradigmClassifierBulkEval -d data/tcga_ov_both_pathwayentities.tab -i data/OV_clinicalTable.txt -c lists/params.txt -l lists/experimentlist.txt -r 40,59 >> temp/exp.out


time scripts/paradigmClassifierBulkEval -d data/tcga_ov_both_pathwayentities.tab -i data/OV_clinicalTable.txt -c lists/cfgExample2.txt  -r 1,10 > temp/exp.out



*/

